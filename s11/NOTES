s11 -- October 2023; Current iteration of Simpleton which uses MongoDB and has a modified Sentence class
 
This version is a series of Python files w/o a main file. 
It also uses MongoDB to store inflections, nnxKB, taggedBoW, taggedCorpus, untaggedCorpus, and webWords.
The Sentence class has been modified to only have basic SVO instance var's. The rest of the POS tag(s) variables
will be added with the given sentence object.

Process order:
   1) processRawCorpus.py       -- Process raw text corpus and sentence starter files, and creates MongoDB collections.
   2) processRawinflections.py  -- Process raw inflection file, and crerates a MongoDB inflection collection.
   3) processRawKB.py           -- Process predefined KB text file for NN and NNP and creates MongoDB KB collections.
   4) rectifyKB.py              -- Attemping to rectify BOW and KB, or add new to webWords (current focus)
   x) processInput.py           -- Process user input


Utilities:
   commonUtils.py    -- Common functions
   checkPickles.py   -- Pickle checker
   simpSA.py         -- Rudimentary sentence analysis
   simpGA.py         -- Was supposed to be a rudimentary grammar analysis * Evolved into kbChecker.py
   kbChecker.py      -- Checks Simp, subject(s), and verbs against KB returns kbRes_Obj
   processOutput.py  -- Plan is to take output of processInput.py and attempt appropriate response
   scrapeWord.py     -- Scrape word definition from web
   addWebWords.py    -- Add new scrpaed words to webWords collection 
   checkWord.py      -- Checks if word exists in tagged corpus, tagged BOW, and KB
   kbChecker.py      -- Different method/form of simpGA.py   

Configuration:
   commonConfig.py   -- Global variables

Sub-Folders:
   Corpus    -- Input docs
   data      -- Starter data and test input
   kb        -- Starter KB data
   pickles   -- Aunt Bees pickle jar

